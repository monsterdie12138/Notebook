
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://monsterdie12138.github.io/Notebook/Computer%20Science/AID/Chapter5/">
      
      
        <link rel="prev" href="../Chapter4/">
      
      
        <link rel="next" href="../Chapter6/">
      
      
      <link rel="icon" href="../../../stylesheets/logo.jpg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.50">
    
    
      
        <title>5.强化学习 - Monsterdie's Notebook</title>
      
    
    
  
      <link rel="stylesheet" href="../../../assets/stylesheets/main.a40c8224.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    

    

      
    
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300i,400,400i,700,700i%7CSource+Code+Pro:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Serif SC";--md-code-font:"Source Code Pro"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-J49VTEQR8G"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-J49VTEQR8G",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-J49VTEQR8G",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter5" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="Monsterdie&#39;s Notebook" class="md-header__button md-logo" aria-label="Monsterdie's Notebook" data-md-component="logo">
      
  <img src="../../../stylesheets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Monsterdie's Notebook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              5.强化学习
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="deep-purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="deep-purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/monsterdie12138/Notebook" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    Monsterdie's Notebook
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Mathematics/" class="md-tabs__link">
          
  
  Mathematics

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  Computer Science

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Course/" class="md-tabs__link">
          
  
  Course

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Monsterdie&#39;s Notebook" class="md-nav__button md-logo" aria-label="Monsterdie's Notebook" data-md-component="logo">
      
  <img src="../../../stylesheets/logo.jpg" alt="logo">

    </a>
    Monsterdie's Notebook
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/monsterdie12138/Notebook" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    Monsterdie's Notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../Mathematics/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Mathematics
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Computer Science
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Computer Science
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../FPA/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    程序设计与算法基础
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../FDS/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    数据结构基础
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ADS/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    高级数据结构与算法分析
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" checked>
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    人工智能引论
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            人工智能引论
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.逻辑与推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.搜索与求解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.机器学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    5.强化学习
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    5.强化学习
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 强化学习的基本概念
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.1 强化学习的基本概念">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      强化学习的基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      马尔可夫决策过程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      策略
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      贝尔曼方程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 基于价值的强化学习
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.2 基于价值的强化学习">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      策略评估方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="策略评估方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      动态规划
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      蒙特卡洛采样
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      时序差分
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      基于价值的强化学习算法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      探索与利用
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.人工智能博弈
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../System1/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    计算机系统Ⅰ
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../System2/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    计算机系统Ⅱ
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../System3/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    计算机系统Ⅲ
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../DB/Chapter1/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    数据库系统
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../Course/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Course
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 强化学习的基本概念
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.1 强化学习的基本概念">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      强化学习的基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      马尔可夫决策过程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      策略
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      贝尔曼方程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 基于价值的强化学习
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.2 基于价值的强化学习">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      策略评估方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="策略评估方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      动态规划
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      蒙特卡洛采样
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      时序差分
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      基于价值的强化学习算法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      探索与利用
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<p><span style="font-family: 'Times New Roman';"></p>
<h1 id="chapter5">Chapter5 强化学习</h1>
<hr />
<h2 id="51">5.1 强化学习的基本概念</h2>
<h3 id="_1">强化学习的基本概念</h3>
<p><strong>强化学习</strong>是智能体在与环境交互中学习能帮助其获得最大化奖励这一策略的过程。在每一次迭代中，智能体根据当前策略选择一个动作，该动作影响环境，导致环境发生改变，智能体此时从环境得到状态变化和奖励反馈等信息，并根据这些反馈更新其内部策略。</p>
<p><img alt="alt text" src="../image/5.7.png" /></p>
<p><strong>形式化描述：</strong></p>
<ul>
<li><strong>智能体：</strong> 强化学习的主体与核心，做出判断与动作</li>
<li><strong>环境：</strong> 智能体以外的一切的统称，能与智能体交互</li>
<li><strong>状态：</strong> 智能体对环境的一种理解和编码，代表对智能体决策产生影响的信息</li>
<li><strong>动作：</strong> 智能体对环境产生影响的方式</li>
<li><strong>策略：</strong> 智能体当前状态下执行动作的依据</li>
<li><strong>奖励：</strong> 智能体采取动作后从环境获得的收益，一般正值代表实际奖励，负值代表实际惩罚</li>
</ul>
<p><strong>特点：</strong></p>
<ul>
<li>基于评估</li>
<li>交互性</li>
<li>序列决策</li>
</ul>
<h3 id="_2">马尔可夫决策过程</h3>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p><strong>让机器人向上或向右从$s_1$移动到$s_9$，不得越界。</strong>
<img alt="alt text" src="../image/5.1.jpg" /></p>
<p>智能体：迷宫机器人 <br />
环境：3×3的方格<br />
状态：机器人在当前时刻所处方格，取值范围为$\{s_1,···,s_9,s_d\}$，$s_d$表示出界状态<br />
动作：向上或向右移动一个方格<br />
奖励：到达$s_9$的正奖励和越界的负奖励，其他时刻不被奖赏也不被惩罚  </p>
</div>
<p><strong>离散随机过程：</strong></p>
<p>一个随机过程实际上是一列随时间变化的随机变量，其中当时间是离散量时，一个随机过程可以表示为$\{S_0,S_1,S_2,···\}$，其中每个$S_t$都是一个随机变量，这被称为<strong>离散随机过程</strong>。</p>
<p><strong>离散马尔可夫过程：</strong></p>
<p>满足<strong>马尔科夫性</strong>（即$S_{t+1}$只与$S_t$相关）的离散随机过程称为<strong>离散马尔可夫过程（马尔科夫链）</strong>。</p>
<div class="admonition success">
<p class="admonition-title">definition</p>
<p><strong>马尔可夫性：</strong> 下一时刻的状态$S_{t+1}$只由当前状态$S_t$决定。<br />
$$P(S_{t+1}=s_{t+1}|S_0=s_0,S_1=s_1,···,S_t=s_t)=P(S_{t+1}=s_{t+1}|S_t=s_t)$$</p>
</div>
<p>现在回到这个问题。</p>
<p><strong>随机变量序列：</strong></p>
<p>$$\{S_0,S_1,S_2,···\}$$</p>
<p>表示机器人的移动过程，$S_t$表示机器人第$t$步所处方格位置，取值范围为$S=\{s_1,s_2,···,s_9,s_d\}$，称为<strong>状态集合</strong>。</p>
<p><strong>状态转移概率：</strong></p>
<p>$$P(S_{t+1}|S_t)$$</p>
<p>满足马尔可夫性。</p>
<p><strong>奖励函数：</strong></p>
<p>$$R(S_t,S_{t+1})$$</p>
<p>表示从第$t$步状态到第$t+1$步状态所获得的奖励，简记为$R_{t+1}$。在机器人寻路问题中，当$S_{t+1}=s_9$时奖励值为1，当$S_{t+1}=s_d$时奖励值为-1，其余情况为0。</p>
<p><strong>回报（反馈）：</strong></p>
<p>$$G_t=R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+···$$</p>
<p>其中，$\gamma\in[0,1]$为<strong>折扣因子（衰退系数）</strong>。</p>
<p>回报反映了某个时刻后所得到累加奖励，当折扣因子小于1时，越是遥远的未来对累加回报的贡献越少。</p>
<p><strong>马尔可夫奖励过程（MRP）：</strong></p>
<p>$$MRP=\{S,P,R,\gamma\}$$</p>
<p>该形式化定义包括状态集、状态转移概率集、奖励集和折扣因子。这个模型虽然能用奖励和回报来刻画智能体的目标，但仍然不能体现其能动性，还缺乏<strong>动作</strong>。</p>
<p><strong>动作集合：</strong></p>
<p>$A=\{up,right\}$</p>
<p>由于引入了动作，所以需要修改状态转移概率为$P(S_{t+1}|S_t,a_t)$，表示在状态$S_t$下采取动作$a_t$转移到状态$S_{t+1}$的概率；修改奖励函数为$R(S_t,a_t,S_{t+1})$，表示状态在$S_t$下采取动作$a_t$转移到状态$S_{t+1}$的奖励。</p>
<p><strong>马尔可夫决策过程（MDP）：</strong></p>
<p>$$MDP=\{S,A,P,R,\gamma\}$$</p>
<p>在马尔可夫奖励过程的基础上引入<strong>动作</strong>。</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p><img alt="alt text" src="../image/5.8.jpg" /></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>一般情况下，初始状态和终止状态并不包含在马尔可夫决策过程的定义中，因为其可被认为是独立于问题的固定状态。本章在定义具体问题时暂时包含。</p>
</div>
<p><strong>轨迹：</strong></p>
<p>马尔可夫过程中产生的状态序列，表示为</p>
<p>$$(S_0,a_0,R_1,S_1,a_1,R_2,S_2,···,S_T)$$</p>
<p>轨迹的长度可以有限也可以无限，有限则为<strong>分段问题</strong>，无限则为<strong>持续问题</strong>。</p>
<p><strong>片段（回合）：</strong></p>
<p>分段问题（有终止状态的问题）中，一个从初始状态到终止状态的完整轨迹称为一个片段（回合）。</p>
<h3 id="_3">策略</h3>
<p><strong>策略函数：</strong></p>
<p>$$\pi:S\times A\mapsto [0,1]$$</p>
<p>其中$\pi(s,a)$表示在状态$s$下采取动作$a$的概率；如果在给定的$s$下只有一个动作选择$a$（确定的），则记为</p>
<p>$$a=\pi(s)$$</p>
<p>一个好的策略函数需要最大化每一时刻的回报值，回报值需要根据一次包含了终止状态的轨迹序列来计算。</p>
<p><strong>价值函数：</strong></p>
<p>$$V:S\mapsto R$$</p>
<p>$$V_{\pi}(s)=E_{\pi}(G_t|S_t=s)$$</p>
<p>表示在第$t$步状态为$s$时，按照策略$\pi$行动后在未来所获得的回报期望。</p>
<p><strong>动作-价值函数：</strong></p>
<p>$$q:S\times A\mapsto R$$</p>
<p>$$q_{\pi}(s,a)=E_{\pi}(G_t|S_t=s,A_t=a)$$</p>
<p>表示在第$t$步状态为$s$时，按照策略$\pi$采取动作$a$后，在未来所获得的回报期望。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>价值函数和动作-价值函数比回报本身更加准确地刻画智能体的目标。</p>
</div>
<p><strong>强化学习问题定义：</strong></p>
<p>给定一个马尔可夫决策过程$MDP=(S,A,P,R,\gamma)$，学习一个最优策略$\pi^<em>$，对任意$s\in S$使得$V_{\pi^</em>}(s)$值最大。</p>
<h3 id="_4">贝尔曼方程</h3>
<p>$$V_{\pi}(s)=\sum\limits_{a\in A}\pi(s,a)q_{\pi}(s,a)~~~~~~~(1)$$</p>
<p>即可用动作-价值函数来表示价值函数。</p>
<p>$$q_{\pi}(s,a)=\sum\limits_{s'\in S}P(s'|s,a)[R(s,a,s')+\gamma V_{\pi}(s')]~~~~~~~(2)$$</p>
<p>即可用价值函数来表示动作-价值函数。</p>
<p>将 <strong>（2）</strong> 代入 <strong>（1）</strong> 得到<strong>价值函数的贝尔曼方程</strong>：</p>
<p>$$V_{\pi}(s)=\sum\limits_{a\in A}\pi(s,a)\sum\limits_{s'\in S}P(s'|s,a)[R(s,a,s')+\gamma V_{\pi}(s')]~~~~~~~(3)$$</p>
<p>说明价值函数取值与时间没有关系，只与策略$\pi$、在策略$\pi$下从某个状态转移到其后续状态所取得的回报以及在后续所得回报有关。</p>
<p>状态$s$可获得的好处$V_{\pi}(s)$由两个部分构成：</p>
<ul>
<li>状态$s$下执行当前动作所得到的瞬时奖励</li>
<li>在后续状态所获得回报期望的折扣值</li>
</ul>
<p>将 <strong>（1）</strong> 代入 <strong>（2）</strong> 得到<strong>动作-价值函数的贝尔曼方程</strong>：</p>
<p>$$q_{\pi}(s,a)=\sum\limits_{s'\in S}P(s'|s,a)[R(s,a,s')+\gamma \sum\limits_{a'\in A}\pi(s,a)q_{\pi}(s',a')]~~~~~~~(4)$$</p>
<p>说明动作-价值函数取值同样与时间没有关系，而是与瞬时奖励和下一步的状态和动作有关。</p>
<p>在状态$s$下采取动作$a$后获得的好处由两个部分组成：</p>
<ul>
<li>在状态$s$下采取动作$a$后带来的瞬时奖励</li>
<li>进入后续状态后，根据当前策略选择动作所得期望回报的折扣值</li>
</ul>
<p>求解最优策略的一种方法就是求解最优的价值函数或者动作-价值函数。</p>
<hr />
<h2 id="52">5.2 基于价值的强化学习</h2>
<p><img alt="alt text" src="../image/5.10.jpg" /></p>
<p>从一个任意的策略开始，首先计算该策略下价值函数或动作-价值函数（<strong>策略评估</strong>），然后根据价值函数调整改进策略使其更优（<strong>策略优化</strong>），不断迭代这个过程直到策略收敛(<strong>通用策略迭代</strong>)。</p>
<p><strong>策略优化定理：</strong></p>
<p>对于确定的策略$\pi$和$\pi'$，如果对于任意状态$s\in S$</p>
<p>$$q_{\pi}(s,\pi'(s))\geqslant q_{\pi}(s,\pi(s))$$</p>
<p>那么对于任意状态$s\in S$，有</p>
<p>$$V_{\pi'}(s)\geqslant V_{\pi}(s)$$</p>
<p>即策略$\pi'$不比$\pi$差。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>注意，$q_{\pi}(s,\pi'(s))$的含义是只在当前这一步将动作修改为$\pi'(s)$，未来的动作仍然按照$\pi$的指导进行。</p>
</div>
<p>优化改进：</p>
<p>$$\forall s\in S,~\pi'(s)=argmax_aq_{\pi}(s,a)$$</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p><img alt="alt text" src="../image/5.11.png" /></p>
<p>$q_{\pi}(s_1,up)=\sum\limits_{s'\in S}P(s'|s_1,up)[R(s_1,up,s')+\gamma V_{\pi}(s')]$<br />
$=1\times(0+0.99\times 0.3)$<br />
$=0.297$<br />
$q_{\pi}(s_1,right)=\sum\limits_{s'\in S}P(s'|s_1,right)[R(s_1,right,s')+\gamma V_{\pi}(s')]$<br />
$=1\times(0+0.99\times 0.4)$<br />
$=0.396$<br />
因此，智能体在$s_1$的策略应改成向右移动。</p>
</div>
<h3 id="_5">策略评估方法</h3>
<p>根据策略$\pi$来计算相应的价值函数$V_{\pi}$或动作-价值函数$q_{\pi}$。</p>
<h4 id="_6">动态规划</h4>
<p>我们已知关于价值函数的贝尔曼方程：</p>
<p>$$V_{\pi}(s)=\sum\limits_{a\in A}\pi(s,a)\sum\limits_{s'\in S}P(s'|s,a)[R(s,a,s')+\gamma V_{\pi}(s')]$$</p>
<p>其中，$\pi$、$P$、$R$都是已知的。如果将每个状态的价值函数都看作未知数，则可以得到$|S|$个方程组成的$|S|$一次方程组。</p>
<p>我们可以用高斯消元法解出所有解，但更好的方法是使用<strong>迭代法</strong>求解，其与<strong>动态规划</strong>的思想不谋而合。在递推关系基础上利用动态规划思想求解价值函数，统称为<strong>策略评估动态规划法</strong>。以下使用的是<strong>高斯-赛德尔迭代法</strong>。</p>
<p><strong>输入：</strong> 策略$\pi$，状态转移概率$P$，奖励函数$R$</p>
<p><strong>输出：</strong> 价值函数$V_{\pi}$</p>
<p><strong>流程：</strong></p>
<ul>
<li>随机初始化$V_{\pi}$，即对于每个状态$s$，给$V_{\pi}(s)$一个随机的初始值</li>
<li>遍历$s\in S$，通过价值函数的贝尔曼方程更新$V_{\pi}(s)$</li>
<li>不断遍历，直到$V_{\pi}$收敛</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>需要事先知道状态转移概率（了解环境的运作机理）</li>
<li>无法处理状态集合很大甚至无限的情况</li>
</ul>
<h4 id="_7">蒙特卡洛采样</h4>
<p>蒙特卡洛采样避免了对转移概率$P$的依赖，用样本均值估计期望。</p>
<p><strong>输入：</strong> 策略$\pi$</p>
<p><strong>输出：</strong> 价值函数$V_{\pi}$</p>
<p><strong>流程：</strong> </p>
<ul>
<li>随机初始化$V_{\pi}$，即对于每个状态$s$，给$V_{\pi}(s)$一个随机的初始值</li>
<li>从可能的起始状态开始按照策略$\pi$采样得到足够多的轨迹$D_1,D_2,···$</li>
<li>对于每一个$s$，在这些轨迹里找到其出现的轨迹，得到这些轨迹里$s$分别对应的回报</li>
<li>将这些回报取平均值即可近似估计$V_{\pi}(s)$，这里用到的是价值函数的最基本定义</li>
</ul>
<p><strong>优点：</strong></p>
<ul>
<li>不依赖状态之间的转移概率</li>
<li>能够将计算资源集中在感兴趣的状态上，以克服状态过多时计算效率低下的问题</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不同轨迹对应的回报可能方差很大，对价值函数的估计不准确</li>
<li>在实际问题中，最终反馈需要在终止状态才能知晓，导致采样轨迹序列较长，反馈周期较长</li>
</ul>
<h4 id="_8">时序差分</h4>
<p>时序差分法可看作蒙特卡洛采样法和动态规划的结合。</p>
<p><strong>输入：</strong> 策略$\pi$</p>
<p><strong>输出：</strong> 价值函数$V_{\pi}$</p>
<p><strong>流程：</strong> </p>
<ul>
<li>随机初始化$V_{\pi}$，即对于每个状态$s$，给$V_{\pi}(s)$一个随机的初始值</li>
<li>随机令某个$s$为初始状态，根据策略$\pi$选择一个动作$a$，更新$V_{\pi}(s)$为$(1-\alpha)V_{\pi}(s)+\alpha[R(s,a,s')+\gamma V_{\pi}(s')]$，更新$s$为$s'$</li>
<li>继续重复上述过程，直到$s$是终止状态</li>
<li>不断重复步骤2、3，直到$V_{\pi}$收敛</li>
</ul>
<p><img alt="alt text" src="../image/5.12.png" /></p>
<p>时序差分同时借鉴了动态规划和蒙特卡洛采样。时序差分与动态规划一样，不断地更新价值函数直到收敛，但其不需要知道转移概率，而是通过采样动作$a$和设置权重$\alpha$来更新；时序差分与蒙特卡洛采样一样，通过采样若干个片段来进行价值函数更新，但其并非使用一个片段中的终止状态所提供的实际回报值来估计价值函数，而是根据下一个状态的价值函数来估计，这样就克服了采样轨迹的稀疏性可能带来样本方差较大的不足问题，同时也缩短了反馈周期。</p>
<h3 id="_9">基于价值的强化学习算法</h3>
<p>现在有了策略优化和策略评估的方法，根据策略迭代的思路，只需要迭代执行这两个步骤，就能得到求解强化学习问题的算法，直观思路如下：</p>
<p><img alt="alt text" src="../image/5.13.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PolicyEvaluation函数可以使用动态规划、蒙特卡洛树采样或时序差分，原本的价值函数改为动作-价值函数。</p>
</div>
<p>出现的问题是：由于策略评估函数本身也是迭代求解的，加上整体的迭代求解会严重影响算法的效率；另一方面，随着迭代次数的增多，动作-价值函数的变化也会越来越小，不足以影响新策略的取值。</p>
<p><strong>价值迭代算法：</strong></p>
<p>以更细的粒度进行策略评估和策略优化。在策略评估动态规划法的基础上，每次迭代只对一个状态进行策略评估和策略优化。</p>
<p><img alt="alt text" src="../image/5.14.png" /></p>
<p><strong>Q学习：</strong></p>
<p>我们已知了不同的策略评估方法，但策略评估只是根据已有策略算出价值，并没有对策略进行修正，完整的强化学习需要策略评估与策略优化，Q学习就是一套相对完整的强化学习流程。</p>
<ul>
<li>随机初始化动作价值函数</li>
<li>随机挑选一个状态$s$开始</li>
<li>在当前状态下找到能带来最大收益的动作$a$</li>
<li>更新对应的动作-价值函数</li>
<li>智能体根据动作$a$来到下一状态</li>
<li>重复第3、4、5步，直到终止，结束内循环</li>
<li>重复第2步，直到收敛，结束外循环</li>
<li>最终策略的确定就是每个状态选择能带来最大收益的动作</li>
</ul>
<p><img alt="alt text" src="../image/5.3.jpg" /></p>
<p>Q学习基于时序差分，直接记录和更新动作-价值函数$q_{\pi}$而不是价值函数$V_{\pi}$，这是因为策略优化要求已知动作-价值函数$q_{\pi}$，如果算法仍然记录价值函数$V_{\pi}$，在不知道状态转移概率的情况下将无法求出$q_{\pi}$。</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p><img alt="alt text" src="../image/5.4.jpg" /><br />
上图是机器人寻路的一次轨迹，方框表示当前机器人的位置，左边数字表示$q_{\pi}(s,up)$，右边数字表示$q_{\pi}(s,right)$。在（a）中，机器人初始状态$s=s_1$，根据Q学习的算法选择动作$a=up$，更新$q_{\pi}(s,up)$（$\alpha=0.5$），更新状态$s$，来到图（b），之后以此类推，直到终止状态，完成一次轨迹的更新。<br />
<img alt="alt text" src="../image/5.5.jpg" />
上图是3次轨迹更新依次对应的结果。  </p>
</div>
<p>但是，如果我们改变$q_{\pi}$的初始化，可能会导致策略的失效。如果外部刺激不足以使机器人尝试新的策略，那么不妨从内部入手为智能体改变固有策略来添加一个探索的动力。</p>
<h3 id="_10">探索与利用</h3>
<p><strong>$\epsilon-$贪心探索策略：</strong></p>
<p>为了使算法摆脱侧重部分状态而忽略剩余状态的情况。</p>
<p>在原本的Q学习算法上作出的唯一改动是：原本的Q学习算法选择动作$a$的依据是当前状态下能得到最大动作-价值函数的动作（$a\leftarrow argmax_{a'}q_{\pi}(s,a')$），而$\epsilon-$贪心策略改为：</p>
<p>$$a\leftarrow\begin{cases}
    argmax_{a'}q_{\pi}(s,a'),p=1-\epsilon\\
    random~a\in A,p=\epsilon
\end{cases}$$</p>
<p>即：在状态$s$，以$1-\epsilon$的概率来选择带来最大回报的动作，或者以$\epsilon$的概率来随机选择一个动作。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>动作$a$的采样策略使用$\epsilon-$贪心策略，但$q_{\pi}(s,a)$的更新策略依然涉及的是最佳选取策略。更新策略与采样策略不同的方法，叫做<strong>离策略方法</strong>。</p>
</div>
<p>但是，依旧存在问题：</p>
<ul>
<li>状态数量过多导致依然有状态无法被采样到</li>
<li>无法用一张表存放无限的$q_{\pi}$</li>
</ul>
<p>解决方法：</p>
<p>将$q_{\pi}$参数化，用一个非线性回归模型（神经网络）来拟合，这样不仅可以用有限的参数刻画无限的状态，由于回归函数的连续型，没有探索过的状态也可通过周围的状态来估计。</p>
<p><strong>深度Q学习：</strong></p>
<p>用深度神经网络拟合$q_{\pi}$，通俗来讲，就是所有的$q_{\pi}$不再需要用表存起来，而是依据原本参数$s$，$a$和额外引进的参数$\theta$映射到某个值。</p>
<p><img alt="alt text" src="../image/5.6.jpg" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>第7行，损失函数$L(\theta)$刻画了$q_{\pi}$的估计值（$R+\gamma\max_{a'}q_{\pi}(s',a';\theta)$）与当前值（$q_{\pi}(s,a;\theta)$）的平方误差。</p>
<p>第8行，利用梯度下降法优化参数$\theta$。</p>
</div>







  
  



  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank" rel="noopener">feedback form</a>. 
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


  <h2 id="__comments">评论</h2>
  <!-- Insert generated snippet here -->
  <script src="https://giscus.app/client.js"
      data-repo="monsterdie12138/Notebook"
      data-repo-id="R_kgDOMQ832g"
      data-category="Announcements"
      data-category-id="DIC_kwDOMQ832s4CmZ2M"
      data-mapping="pathname"
      data-strict="0"
      data-reactions-enabled="1"
      data-emit-metadata="0"
      data-input-position="bottom"
      data-theme="preferred_color_scheme"
      data-lang="zh-CN"
      crossorigin="anonymous"
      async>
  </script>
  <!-- Synchronize Giscus theme with palette -->
  <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate"
        ? "transparent_dark"
        : "light"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after document loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate"
            ? "transparent_dark"
            : "light"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>

                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../Chapter4/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 4.深度学习">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                4.深度学习
              </div>
            </div>
          </a>
        
        
          
          <a href="../Chapter6/" class="md-footer__link md-footer__link--next" aria-label="下一页: 6.人工智能博弈">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                6.人工智能博弈
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - Now Monsterdie
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/monsterdie12138" target="_blank" rel="noopener" title="Writer on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.path", "navigation.top", "navigation.footer", "navigation.prune", "search.suggest", "content.code.copy", "content.code.select", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.60a45f97.min.js"></script>
      
    
  </body>
</html>